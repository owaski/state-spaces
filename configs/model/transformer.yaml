# Large Transformer model used as baseline for WikiText-103
defaults:
  - base
  - override layer: transformer

encoder:
  _name_: position
  dropout: ${..dropout}

n_layers: 1
d_model: 16
